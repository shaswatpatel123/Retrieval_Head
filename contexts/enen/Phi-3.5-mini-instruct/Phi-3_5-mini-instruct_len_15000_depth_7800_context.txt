

Want to start a startup?  Get funded by
Y Combinator.




April 2001, rev. April 2003(This article is derived from a talk given at the 2001 Franz
Developer Symposium.)
In the summer of 1995, my friend Robert Morris and I
started a startup called 
Viaweb.  
Our plan was to write
software that would let end users build online stores.
What was novel about this software, at the time, was
that it ran on our server, using ordinary Web pages
as the interface.A lot of people could have been having this idea at the
same time, of course, but as far as I know, Viaweb was
the first Web-based application.  It seemed such
a novel idea to us that we named the company after it:
Viaweb, because our software worked via the Web,
instead of running on your desktop computer.Another unusual thing about this software was that it
was written primarily in a programming language called
Lisp. It was one of the first big end-user
applications to be written in Lisp, which up till then
had been used mostly in universities and research labs. [1]The Secret WeaponEric Raymond has written an essay called "How to Become a Hacker,"
and in it, among other things, he tells would-be hackers what
languages they should learn.  He suggests starting with Python and
Java, because they are easy to learn.  The serious hacker will also
want to learn C, in order to hack Unix, and Perl for system
administration and cgi scripts.  Finally, the truly serious hacker
should consider learning Lisp:

  Lisp is worth learning for the profound enlightenment experience
  you will have when you finally get it; that experience will make
  you a better programmer for the rest of your days, even if you
  never actually use Lisp itself a lot.

This is the same argument you tend to hear for learning Latin.  It
won't get you a job, except perhaps as a classics professor, but
it will improve your mind, and make you a better writer in languages
you do want to use, like English.But wait a minute.  This metaphor doesn't stretch that far.  The
reason Latin won't get you a job is that no one speaks it.  If you
write in Latin, no one can understand you.  But Lisp is a computer
language, and computers speak whatever language you, the programmer,
tell them to.So if Lisp makes you a better programmer, like he says, why wouldn't
you want to use it? If a painter were offered a brush that would
make him a better painter, it seems to me that he would want to
use it in all his paintings, wouldn't he? I'm not trying to make
fun of Eric Raymond here.  On the whole, his advice is good.  What
he says about Lisp is pretty much the conventional wisdom.  But
there is a contradiction in the conventional wisdom:  Lisp will
make you a better programmer, and yet you won't use it.Why not?  Programming languages are just tools, after all.  If Lisp
really does yield better programs, you should use it.  And if it
doesn't, then who needs it?This is not just a theoretical question.  Software is a very
competitive business, prone to natural monopolies.  A company that
gets software written faster and better will, all other things
being equal, put its competitors out of business.  And when you're
starting a startup, you feel this very keenly.  Startups tend to
be an all or nothing proposition.  You either get rich, or you get
nothing.  In a startup, if you bet on the wrong technology, your
competitors will crush you.Robert and I both knew Lisp well, and we couldn't see any reason
not to trust our instincts and go with Lisp.  We knew that everyone
else was writing their software in C++ or Perl.  But we also knew
that that didn't mean anything.  If you chose technology that way,
you'd be running Windows.  When you choose technology, you have to
ignore what other people are doing, and consider only what will
work the best.This is especially true in a startup.  In a big company, you can
do what all the other big companies are doing.  But a startup can't
do what all the other startups do.  I don't think a lot of people
realize this, even in startups.The average big company grows at about ten percent a year.  So if
you're running a big company and you do everything the way the
average big company does it, you can expect to do as well as the
average big company-- that is, to grow about ten percent a year.The same thing will happen if you're running a startup, of course.
If you do everything the way the average startup does it, you should
expect average performance.  The problem here is, average performance
means that you'll go out of business.  The survival rate for startups
is way less than fifty percent.  So if you're running a startup,
you had better be doing something odd.  If not, you're in trouble.Back in 1995, we knew something that I don't think our competitors
understood, and few understand even now:  when you're writing
software that only has to run on your own servers, you can use
any language you want.  When you're writing desktop software,
there's a strong bias toward writing applications in the same
language as the operating system.  Ten years ago, writing applications
meant writing applications in C.  But with Web-based software,
especially when you have the source code of both the language and
the operating system, you can use whatever language you want.This new freedom is a double-edged sword, however.  Now that you
can use any language, you have to think about which one to use.
Companies that try to pretend nothing has changed risk finding that
their competitors do not.If you can use any language, which do you use?  We chose Lisp.
For one thing, it was obvious that rapid development would be
important in this market.  We were all starting from scratch, so
a company that could get new features done before its competitors
would have a big advantage.  We knew Lisp was a really good language
for writing software quickly, and server-based applications magnify
the effect of rapid development, because you can release software
the minute it's done.If other companies didn't want to use Lisp, so much the better.
It might give us a technological edge, and we needed all the help
we could get.  When we started Viaweb, we had no experience in
business.  We didn't know anything about marketing, or hiring
people, or raising money, or getting customers.  Neither of us had
ever even had what you would call a real job.  The only thing we
were good at was writing software.  We hoped that would save us.
Any advantage we could get in the software department, we would
take.So you could say that using Lisp was an experiment.  Our hypothesis
was that if we wrote our software in Lisp, we'd be able to get
features done faster than our competitors, and also to do things
in our software that they couldn't do.  And because Lisp was so
high-level, we wouldn't need a big development team, so our costs
would be lower.  If this were so, we could offer a better product
for less money, and still make a profit.  We would end up getting
all the users, and our competitors would get none, and eventually
go out of business.  That was what we hoped would happen, anyway.What were the results of this experiment?  Somewhat surprisingly,
it worked.  We eventually had many competitors, on the order of
twenty to thirty of them, but none of their software could compete
with ours.  We had a wysiwyg online store builder that ran on the
server and yet felt like a desktop application.  Our competitors
had cgi scripts.  And we were always far ahead of them in features.
Sometimes, in desperation, competitors would try to introduce
features that we didn't have.  But with Lisp our development cycle
was so fast that we could sometimes duplicate a new feature within
a day or two of a competitor announcing it in a press release.  By
the time journalists covering the press release got round to calling
us, we would have the new feature too.It must have seemed to our competitors that we had some kind of
secret weapon-- that we were decoding their Enigma traffic or
something.  In fact we did have a secret weapon, but it was simpler
than they realized.  No one was leaking news of their features to
us.   We were just able to develop software faster than anyone
thought possible.When I was about nine I happened to get hold of a copy of The Day
of the Jackal, by Frederick Forsyth.  The main character is an
assassin who is hired to kill the president of France.  The assassin
has to get past the police to get up to an apartment that overlooks
the president's route.  He walks right by them, dressed up as an
old man on crutches, and they never suspect him.Our secret weapon was similar.  We wrote our software in a weird
AI language, with a bizarre syntax full of parentheses.  For years
it had annoyed me to hear Lisp described that way.  But now it
worked to our advantage.  In business, there is nothing more valuable
than a technical advantage your competitors don't understand.  In
business, as in war, surprise is worth as much as force.And so, I'm a little embarrassed to say, I never said anything
publicly about Lisp while we were working on Viaweb.  We never
mentioned it to the press, and if you searched for Lisp on our Web
site, all you'd find were the titles of two books in my bio.  This
was no accident.  A startup should give its competitors as little
information as possible.  If they didn't know what language our
software was written in, or didn't care, I wanted to keep it that
way.[2]The people who understood our technology best were the customers.
They didn't care what language Viaweb was written in either, but
they noticed that it worked really well.  It let them build great
looking online stores literally in minutes.  And so, by word of
mouth mostly, we got more and more users.  By the end of 1996 we
had about 70 stores online.  At the end of 1997 we had 500.  Six
months later, when Yahoo bought us, we had 1070 users.  Today, as
Yahoo Store, this software continues to dominate its market.  It's
one of the more profitable pieces of Yahoo, and the stores built
with it are the foundation of Yahoo Shopping.  I left Yahoo in
1999, so I don't know exactly how many users they have now, but
the last I heard there were about 20,000.
The Blub ParadoxWhat's so great about Lisp?  And if Lisp is so great, why doesn't
everyone use it?  These sound like rhetorical questions, but actually
they have straightforward answers.  Lisp is so great not because
of some magic quality visible only to devotees, but because it is
simply the most powerful language available.  And the reason everyone
doesn't use it is that programming languages are not merely
technologies, but habits of mind as well, and nothing changes
slower.  Of course, both these answers need explaining.I'll begin with a shockingly controversial statement:  programming
languages vary in power.Few would dispute, at least, that high level languages are more
powerful than machine language.  Most programmers today would agree
that you do not, ordinarily, want to program in machine language.
Instead, you should program in a high-level language, and have a
compiler translate it into machine language for you.  This idea is
even built into the hardware now: since the 1980s, instruction sets
have been designed for compilers rather than human programmers.Everyone knows it's a mistake to write your whole program by hand
in machine language.  What's less often understood is that there
is a more general principle here: that if you have a choice of
several languages, it is, all other things being equal, a mistake
to program in anything but the most powerful one. [3]There are many exceptions to this rule.  If you're writing a program
that has to work very closely with a program written in a certain
language, it might be a good idea to write the new program in the
same language.  If you're writing a program that only has to do
something very simple, like number crunching or bit manipulation,
you may as well use a less abstract language, especially since it
may be slightly faster.  And if you're writing a short, throwaway
program, you may be better off just using whatever language has
the best library functions for the task.  But in general, for
application software, you want to be using the most powerful
(reasonably efficient) language you can get, and using anything
else is a mistake, of exactly the same kind, though possibly in a
lesser degree, as programming in machine language.You can see that machine language is very low level.  But, at least
as a kind of social convention, high-level languages are often all
treated as equivalent.  They're not.  Technically the term "high-level
language" doesn't mean anything very definite.  There's no dividing
line with machine languages on one side and all the high-level
languages on the other.  Languages fall along a continuum [4] of
abstractness, from the most powerful all the way down to machine
languages, which themselves vary in power.Consider Cobol.  Cobol is a high-level language, in the sense that
it gets compiled into machine language.  Would anyone seriously
argue that Cobol is equivalent in power to, say, Python?  It's
probably closer to machine language than Python.Or how about Perl 4?  Between Perl 4 and Perl 5, lexical closures
got added to the language.  Most Perl hackers would agree that Perl
5 is more powerful than Perl 4.  But once you've admitted that,
you've admitted that one high level language can be more powerful
than another.  And it follows inexorably that, except in special
cases, you ought to use the most powerful you can get.This idea is rarely followed to its conclusion, though.  After a
certain age, programmers rarely switch languages voluntarily.
Whatever language people happen to be used to, they tend to consider
just good enough.Programmers get very attached to their favorite languages, and I
don't want to hurt anyone's feelings, so to explain this point I'm
going to use a hypothetical language called Blub.  Blub falls right
in the middle of the abstractness continuum.  It is not the most
powerful language, but it is more powerful than Cobol or machine
language.And in fact, our hypothetical Blub programmer wouldn't use either
of them.  Of course he wouldn't program in machine language.  That's
what compilers are for.  And as for Cobol, he doesn't know how
anyone can get anything done with it.  It doesn't even have x (Blub
feature of your choice).As long as our hypothetical Blub programmer is looking down the
power continuum, he knows he's looking down.  Languages less powerful
than Blub are obviously less powerful, because they're missing some
feature he's used to.  But when our hypothetical Blub programmer
looks in the other direction, up the power continuum, he doesn't
realize he's looking up.  What he sees are merely weird languages.
He probably considers them about equivalent in power to Blub, but
with all this other hairy stuff thrown in as well.  Blub is good
enough for him, because he thinks in Blub.When we switch to the point of view of a programmer using any of
the languages higher up the power continuum, however, we find that
he in turn looks down upon Blub.  How can you get anything done in
Blub? It doesn't even have y.By induction, the only programmers in a position to see all the
differences in power between the various languages are those who
understand the most powerful one.  (This is probably what Eric
Raymond meant about Lisp making you a better programmer.) You can't
trust the opinions of the others, because of the Blub paradox:
they're satisfied with whatever language they happen to use, because
it dictates the way they think about programs.I know this from my own experience, as a high school kid writing
programs in Basic.  That language didn't even support recursion.
It's hard to imagine writing programs without using recursion, but
I didn't miss it at the time.  I thought in Basic.  And I was a
whiz at it.  Master of all I surveyed.The five languages that Eric Raymond recommends to hackers fall at
various points on the power continuum.  Where they fall relative
to one another is a sensitive topic.  What I will say is that I
think Lisp is at the top.  And to support this claim I'll tell you
about one of the things I find missing when I look at the other
four languages.  How can you get anything done in them, I think,
without macros? [5]Many languages have something called a macro.  But Lisp macros are
unique.  And believe it or not, what they do is related to the
parentheses.  The designers of Lisp didn't put all those parentheses
in the language just to be different.  To the Blub programmer, Lisp
code looks weird.  But those parentheses are there for a reason.
They are the outward evidence of a fundamental difference between
Lisp and other languages.Lisp code is made out of Lisp data objects.  And not in the trivial
sense that the source files contain characters, and strings are
one of the data types supported by the language.  Lisp code, after
it's read by the parser, is made of data structures that you can
traverse.If you understand how compilers work, what's really going on is
not so much that Lisp has a strange syntax as that Lisp has no
syntax.  You write programs in the parse trees that get generated
within the compiler when other languages are parsed.  But these
parse trees are fully accessible to your programs.  You can write
programs that manipulate them.  In Lisp, these programs are called
macros.  They are programs that write programs.Programs that write programs?  When would you ever want to do that?
Not very often, if you think in Cobol.  All the time, if you think
in Lisp.  It would be convenient here if I could give an example
of a powerful macro, and say there! how about that?  But if I did,
it would just look like gibberish to someone who didn't know Lisp;
there isn't room here to explain everything you'd need to know to
understand what it meant.  In 
Ansi Common Lisp I tried to move
things along as fast as I could, and even so I didn't get to macros
until page 160.But I think I can give a kind of argument that might be convincing.
The source code of the Viaweb editor was probably about 20-25%
macros.  Macros are harder to write than ordinary Lisp functions,
and it's considered to be bad style to use them when they're not
necessary.  So every macro in that code is there because it has to
be.  What that means is that at least 20-25% of the code in this
program is doing things that you can't easily do in any other
language.  However skeptical the Blub programmer might be about my
claims for the mysterious powers of Lisp, this ought to make him
curious.  We weren't writing this code for our own amusement.  We
were a tiny startup, programming as hard as we could in order to
put technical barriers between us and our competitors.A suspicious person might begin to wonder if there was some
correlation here.  A big chunk of our code was doing things that
are very hard to do in other languages.  The resulting software
did things our competitors' software couldn't do.  Maybe there was
some kind of connection.  I encourage you to follow that thread.
There may be more to that old man hobbling along on his crutches
than meets the eye.Aikido for StartupsBut I don't expect to convince anyone 
(over 25) 
to go out and learn
Lisp.  The purpose of this article is not to change anyone's mind,
but to reassure people already interested in using Lisp-- people
who know that Lisp is a powerful language, but worry because it
isn't widely used.  In a competitive situation, that's an advantage.
Lisp's power is multiplied by the fact that your competitors don't
get it.If you think of using Lisp in a startup, you shouldn't worry that
it isn't widely understood.  You should hope that it stays that
way. And it's likely to.  It's the nature of programming languages
to make most people satisfied with whatever they currently use.
Computer hardware changes so much faster than personal habits that
programming practice is usually ten to twenty years behind the
processor.  At places like MIT they were writing programs in
high-level languages in the early 1960s, but many companies continued
to write code in machine language well into the 1980s.  I bet a
lot of people continued to write machine language until the processor,
like a bartender eager to close up and go home, finally kicked them
out by switching to a risc instruction set.Ordinarily technology changes fast.  But programming languages are
different: programming languages are not just technology, but what
programmers think in.  They're half technology and half religion.[6]
And so the median language, meaning whatever language the median
programmer uses, moves as slow as an iceberg.  Garbage collection,
introduced by Lisp in about 1960, is now widely considered to be
a good thing.  Runtime typing, ditto, is growing in popularity.
Lexical closures, introduced by Lisp in the early 1970s, are now,
just barely, on the radar screen.  Macros, introduced by Lisp in the
mid 1960s, are still terra incognita.Obviously, the median language has enormous momentum.  I'm not
proposing that you can fight this powerful force.  What I'm proposing
is exactly the opposite: that, like a practitioner of Aikido, you
can use it against your opponents.If you work for a big company, this may not be easy.  You will have
a hard time convincing the pointy-haired boss to let you build
things in Lisp, when he has just read in the paper that some other
language is poised, like Ada was twenty years ago, to take over
the world.  But if you work for a startup that doesn't have
pointy-haired bosses yet, you can, like we did, turn the Blub
paradox to your advantage:  you can use technology that your
competitors, glued immovably to the median language, will never be
able to match.If you ever do find yourself working for a startup, here's a handy
tip for evaluating competitors.  Read their job listings.  Everything
else on their site may be stock photos or the prose equivalent,
but the job listings have to be specific about what they want, or
they'll get the wrong candidates.During the years we worked on Viaweb I read a lot of job descriptions.
A new competitor seemed to emerge out of the woodwork every month
or so.  The first thing I would do, after checking to see if they
had a live online demo, was look at their job listings.  After a
couple years of this I could tell which companies to worry about
and which not to.  The more of an IT flavor the job descriptions
had, the less dangerous the company was.  The safest kind were the
ones that wanted Oracle experience.  You never had to worry about
those.  You were also safe if they said they wanted C++ or Java
developers.  If they wanted Perl or Python programmers, that would
be a bit frightening-- that's starting to sound like a company
where the technical side, at least, is run by real hackers.  If I
had ever seen a job posting looking for Lisp hackers, I would have
been really worried.
Notes[1] Viaweb at first had two parts: the editor, written in Lisp,
which people used to build their sites, and the ordering system,
written in C, which handled orders.  The first version was mostly
Lisp, because the ordering system was small.  Later we added two
more modules, an image generator written in C, and a back-office
manager written mostly in Perl.In January 2003, Yahoo released a new version of the editor 
written in C++ and Perl.  It's hard to say whether the program is no
longer written in Lisp, though, because to translate this program
into C++ they literally had to write a Lisp interpreter: the source
files of all the page-generating templates are still, as far as I
know,  Lisp code.  (See Greenspun's Tenth Rule.)[2] Robert Morris says that I didn't need to be secretive, because
even if our competitors had known we were using Lisp, they wouldn't
have understood why:  "If they were that smart they'd already be
programming in Lisp."[3] All languages are equally powerful in the sense of being Turing
equivalent, but that's not the sense of the word programmers care
about. (No one wants to program a Turing machine.)  The kind of
power programmers care about may not be formally definable, but
one way to explain it would be to say that it refers to features
you could only get in the less powerful language by writing an
interpreter for the more powerful language in it. If language A
has an operator for removing spaces from strings and language B
doesn't, that probably doesn't make A more powerful, because you
can probably write a subroutine to do it in B.  But if A supports,
say, recursion, and B doesn't, that's not likely to be something
you can fix by writing library functions.[4] Note to nerds: or possibly a lattice, narrowing toward the top;
it's not the shape that matters here but the idea that there is at
least a partial order.[5] It is a bit misleading to treat macros as a separate feature.
In practice their usefulness is greatly enhanced by other Lisp
features like lexical closures and rest parameters.[6] As a result, comparisons of programming languages either take
the form of religious wars or undergraduate textbooks so determinedly
neutral that they're really works of anthropology.  People who
value their peace, or want tenure, avoid the topic.  But the question
is only half a religious one; there is something there worth
studying, especially if you want to design new languages.November 2021(This essay is derived from a talk at the Cambridge Union.)When I was a kid, I'd have said there wasn't. My father told me so.
Some people like some things, and other people like other things,
and who's to say who's right?It seemed so obvious that there was no such thing as good taste
that it was only through indirect evidence that I realized my father
was wrong. And that's what I'm going to give you here: a proof by
reductio ad absurdum. If we start from the premise that there's no
such thing as good taste, we end up with conclusions that are
obviously false, and therefore the premise must be wrong.We'd better start by saying what good taste is. There's a narrow
sense in which it refers to aesthetic judgements and a broader one
in which it refers to preferences of any kind. The strongest proof
would be to show that taste exists in the narrowest sense, so I'm
going to talk about taste in art. You have better taste than me if
the art you like is better than the art I like.If there's no such thing as good taste, then there's no such thing
as good art. Because if there is such a
thing as good art, it's
easy to tell which of two people has better taste. Show them a lot
of works by artists they've never seen before and ask them to
choose the best, and whoever chooses the better art has better
taste.So if you want to discard the concept of good taste, you also have
to discard the concept of good art. And that means you have to
discard the possibility of people being good at making it. Which
means there's no way for artists to be good at their jobs. And not
just visual artists, but anyone who is in any sense an artist. You
can't have good actors, or novelists, or composers, or dancers
either. You can have popular novelists, but not good ones.We don't realize how far we'd have to go if we discarded the concept
of good taste, because we don't even debate the most obvious cases.
But it doesn't just mean we can't say which of two famous painters
is better. It means we can't say that any painter is better than a
randomly chosen eight year old.That was how I realized my father was wrong. I started studying
painting. And it was just like other kinds of work I'd done: you
could do it well, or badly, and if you tried hard, you could get
better at it. And it was obvious that Leonardo and Bellini were
much better at it than me. That gap between us was not imaginary.
They were so good. And if they could be good, then art could be
good, and there was such a thing as good taste after all.Now that I've explained how to show there is such a thing as good
taste, I should also explain why people think there isn't. There
are two reasons. One is that there's always so much disagreement
about taste. Most people's response to art is a tangle of unexamined
impulses. Is the artist famous? Is the subject attractive? Is this
the sort of art they're supposed to like? Is it hanging in a famous
museum, or reproduced in a big, expensive book? In practice most
people's response to art is dominated by such extraneous factors.And the people who do claim to have good taste are so often mistaken.
The paintings admired by the so-called experts in one generation
are often so different from those admired a few generations later.
It's easy to conclude there's nothing real there at all. It's only
when you isolate this force, for example by trying to paint and
comparing your work to Bellini's, that you can see that it does in
fact exist.The other reason people doubt that art can be good is that there
doesn't seem to be any room in the art for this goodness. The
argument goes like this. Imagine several people looking at a work
of art and judging how good it is. If being good art really is a
property of objects, it should be in the object somehow. But it
doesn't seem to be; it seems to be something happening in the heads
of each of the observers. And if they disagree, how do you choose
between them?The solution to this puzzle is to realize that the purpose of art
is to work on its human audience, and humans have a lot in common.
And to the extent the things an object acts upon respond in the
same way, that's arguably what it means for the object to have the
corresponding property. If everything a particle interacts with
behaves as if the particle had a mass of m, then it has a mass of
m. So the distinction between "objective" and "subjective" is not
binary, but a matter of degree, depending on how much the subjects
have in common. Particles interacting with one another are at one
pole, but people interacting with art are not all the way at the
other; their reactions aren't random.Because people's responses to art aren't random, art can be designed
to operate on people, and be good or bad depending on how effectively
it does so. Much as a vaccine can be. If someone were talking about
the ability of a vaccine to confer immunity, it would seem very
frivolous to object that conferring immunity wasn't really a property
of vaccines, because acquiring immunity is something that happens
in the immune system of each individual person. Sure, people's
immune systems vary, and a vaccine that worked on one might not
work on another, but that doesn't make it meaningless to talk about
the effectiveness of a vaccine.The situation with art is messier, of course. You can't measure
effectiveness by simply taking a vote, as you do with vaccines.
You have to imagine the responses of subjects with a deep knowledge
of art, and enough clarity of mind to be able to ignore extraneous
influences like the fame of the artist. And even then you'd still
see some disagreement. People do vary, and judging art is hard,
especially recent art. There is definitely not a total order either
of works or of people's ability to judge them. But there is equally
definitely a partial order of both. So while it's not possible to
have perfect taste, it is possible to have good taste.
Thanks to the Cambridge Union for inviting me, and to Trevor
Blackwell, Jessica Livingston, and Robert Morris for reading drafts
of this.
May 2021There's one kind of opinion I'd be very afraid to express publicly.
If someone I knew to be both a domain expert and a reasonable person
proposed an idea that sounded preposterous, I'd be very reluctant
to say "That will never work."Anyone who has studied the history of ideas, and especially the
history of science, knows that's how big things start. Someone
proposes an idea that sounds crazy, most people dismiss it, then
it gradually takes over the world.Most implausible-sounding ideas are in fact bad and could be safely
dismissed. But not when they're proposed by reasonable domain
experts. If the person proposing the idea is reasonable, then they
know how implausible it sounds. And yet they're proposing it anyway.
That suggests they know something you don't. And if they have deep
domain expertise, that's probably the source of it.
[1]Such ideas are not merely unsafe to dismiss, but disproportionately
likely to be interesting. When the average person proposes an
implausible-sounding idea, its implausibility is evidence of their
incompetence. But when a reasonable domain expert does it, the
situation is reversed. There's something like an efficient market
here: on average the ideas that seem craziest will, if correct,
have the biggest effect. So if you can eliminate the theory that
the person proposing an implausible-sounding idea is incompetent,
its implausibility switches from evidence that it's boring to
evidence that it's exciting.
[2]Such ideas are not guaranteed to work. But they don't have to be.
They just have to be sufficiently good bets — to have sufficiently
high expected value. And I think on average they do. I think if you
bet on the entire set of implausible-sounding ideas proposed by
reasonable domain experts, you'd end up net ahead.The reason is that everyone is too conservative. The word "paradigm"
is overused, but this is a case where it's warranted. Everyone is
too much in the grip of the current paradigm. Even the people who
have the new ideas undervalue them initially. Which means that
before they reach the stage of proposing them publicly, they've
already subjected them to an excessively strict filter.
[3]The wise response to such an idea is not to make statements, but
to ask questions, because there's a real mystery here. Why has this
smart and reasonable person proposed an idea that seems so wrong?
Are they mistaken, or are you? One of you has to be. If you're the
one who's mistaken, that would be good to know, because it means
there's a hole in your model of the world. But even if they're
mistaken, it should be interesting to learn why. A trap that an
expert falls into is one you have to worry about too.This all seems pretty obvious. And yet there are clearly a lot of
people who don't share my fear of dismissing new ideas. Why do they
do it? Why risk looking like a jerk now and a fool later, instead
of just reserving judgement?One reason they do it is envy. If you propose a radical new idea
and it succeeds, your reputation (and perhaps also your wealth)
will increase proportionally. Some people would be envious if that
happened, and this potential envy propagates back into a conviction
that you must be wrong.Another reason people dismiss new ideas is that it's an easy way
to seem sophisticated. When a new idea first emerges, it usually
seems pretty feeble. It's a mere hatchling. Received wisdom is a
full-grown eagle by comparison. So it's easy to launch a devastating
attack on a new idea, and anyone who does will seem clever to those
who don't understand this asymmetry.This phenomenon is exacerbated by the difference between how those
working on new ideas and those attacking them are rewarded. The
rewards for working on new ideas are weighted by the value of the
outcome. So it's worth working on something that only has a 10%
chance of succeeding if it would make things more than 10x better.
Whereas the rewards for attacking new ideas are roughly constant;
such attacks seem roughly equally clever regardless of the target.People will also attack new ideas when they have a vested interest
in the old ones. It's not surprising, for example, that some of
Darwin's harshest critics were churchmen. People build whole careers
on some ideas. When someone claims they're false or obsolete, they
feel threatened.The lowest form of dismissal is mere factionalism: to automatically
dismiss any idea associated with the opposing faction. The lowest
form of all is to dismiss an idea because of who proposed it.But the main thing that leads reasonable people to dismiss new ideas
is the same thing that holds people back from proposing them: the
sheer pervasiveness of the current paradigm. It doesn't just affect
the way we think; it is the Lego blocks we build thoughts out of.
Popping out of the current paradigm is something only a few people
can do. And even they usually have to suppress their intuitions at
first, like a pilot flying through cloud who has to trust his
instruments over his sense of balance.
[4]Paradigms don't just define our present thinking. They also vacuum
up the trail of crumbs that led to them, making our standards for
new ideas impossibly high. The current paradigm seems so perfect
to us, its offspring, that we imagine it must have been accepted
completely as soon as it was discovered — that whatever the church thought
of the heliocentric model, astronomers must have been convinced as
soon as Copernicus proposed it. Far, in fact, from it. Copernicus
published the heliocentric model in 1532, but it wasn't till the
mid seventeenth century that the balance of scientific opinion
shifted in its favor.
[5]Few understand how feeble new ideas look when they first appear.
So if you want to have new ideas yourself, one of the most valuable
things you can do is to learn what they look like when they're born.
Read about how new ideas happened, and try to get yourself into the
heads of people at the time. How did things look to them, when the
new idea was only half-finished, and even the person who had it was
only half-convinced it was right?But you don't have to stop at history. You can observe big new ideas
being born all around you right now. Just look for a reasonable
domain expert proposing something that sounds wrong.If you're nice, as well as wise, you won't merely resist attacking
such people, but encourage them. Having new ideas is a lonely
business. Only those who've tried it know how lonely. These people
need your help. And if you help them, you'll probably learn something
in the process.Notes[1]
This domain expertise could be in another field. Indeed,
such crossovers tend to be particularly promising.[2]
I'm not claiming this principle extends much beyond math,
engineering, and the hard sciences. In politics, for example,
crazy-sounding ideas generally are as bad as they sound. Though
arguably this is not an exception, because the people who propose
them are not in fact domain experts; politicians are domain experts
in political tactics, like how to get elected and how to get
legislation passed, but not in the world that policy acts upon.
Perhaps no one could be.[3]
This sense of "paradigm" was defined by Thomas Kuhn in his
Structure of Scientific Revolutions, but I also recommend his
Copernican Revolution, where you can see him at work developing the
idea.[4]
This is one reason people with a touch of Asperger's may have
an advantage in discovering new ideas. They're always flying on
instruments.[5]
Hall, Rupert. From Galileo to Newton. Collins, 1963. This
book is particularly good at getting into contemporaries' heads.Thanks to Trevor Blackwell, Patrick Collison, Suhail Doshi, Daniel
Gackle, Jessica Livingston, and Robert Morris for reading drafts of this.

Want to start a startup?  Get funded by
Y Combinator.




October 2010After barely changing at all for decades, the startup funding
business is now in what could, at least by comparison, be called
turmoil.  At Y Combinator we've seen dramatic changes in the funding
environment for startups.  Fortunately one of them is much higher
valuations.The trends we've been seeing are probably not YC-specific.  I wish
I could say they were, but the main cause is probably just that we
see trends first—partly because the startups we fund are very
plugged into the Valley and are quick to take advantage of anything
new, and partly because we fund so many that we have enough data
points to see patterns clearly.What we're seeing now, everyone's probably going to be seeing in
the next couple years.  So I'm going to explain what we're seeing,
and what that will mean for you if you try to raise money.Super-AngelsLet me start by describing what the world of startup funding used
to look like.  There used to be two sharply differentiated types
of investors: angels and venture capitalists.  Angels are individual
rich people who invest small amounts of their own money, while VCs
are employees of funds that invest large amounts of other people's.For decades there were just those two types of investors, but now
a third type has appeared halfway between them: the so-called
super-angels. 
[1]
  And VCs have been provoked by their arrival
into making a lot of angel-style investments themselves.  So the
previously sharp line between angels and VCs has become hopelessly
blurred.There used to be a no man's land between angels and VCs.  Angels
would invest $20k to $50k apiece, and VCs usually a million or more.
So an angel round meant a collection of angel investments that
combined to maybe $200k, and a VC round meant a series A round in
which a single VC fund (or occasionally two) invested $1-5 million.The no man's land between angels and VCs was a very inconvenient
one for startups, because it coincided with the amount many wanted
to raise.  Most startups coming out of Demo Day wanted to raise
around $400k.  But it was a pain to stitch together that much out
of angel investments, and most VCs weren't interested in investments
so small.  That's the fundamental reason the super-angels have
appeared.  They're responding to the market.The arrival of a new type of investor is big news for startups,
because there used to be only two and they rarely competed with one
another.  Super-angels compete with both angels and VCs.  That's
going to change the rules about how to raise money.  I don't know
yet what the new rules will be, but it looks like most of the changes
will be for the better.A super-angel has some of the qualities of an angel, and some of
the qualities of a VC.  They're usually individuals, like angels.
In fact many of the current super-angels were initially angels of
the classic type.  But like VCs, they invest other people's money.
This allows them to invest larger amounts than angels:  a typical
super-angel investment is currently about $100k.  They make investment
decisions quickly, like angels.  And they make a lot more investments
per partner than VCs—up to 10 times as many.The fact that super-angels invest other people's money makes them
doubly alarming to VCs. They don't just compete for startups; they
also compete for investors.  What super-angels really are is a new
form of fast-moving, lightweight VC fund.   And those of us in the
technology world know what usually happens when something comes
along that can be described in terms like that.  Usually it's the
replacement.Will it be?  As of now, few of the startups that take money from
super-angels are ruling out taking VC money.  They're just postponing
it.  But that's still a problem for VCs.  Some of the startups that
postpone raising VC money may do so well on the angel money they
raise that they never bother to raise more.  And those who do raise
VC rounds will be able to get higher valuations when they do.  If
the best startups get 10x higher valuations when they raise series
A rounds, that would cut VCs' returns from winners at least tenfold.
[2]So I think VC funds are seriously threatened by the super-angels.
But one thing that may save them to some extent is the uneven
distribution of startup outcomes: practically all the returns are
concentrated in a few big successes.  The expected value of a startup
is the percentage chance it's Google.  So to the extent that winning
is a matter of absolute returns, the super-angels could win practically
all the battles for individual startups and yet lose the war, if
they merely failed to get those few big winners.  And there's a
chance that could happen, because the top VC funds have better
brands, and can also do more for their portfolio companies.  
[3]Because super-angels make more investments per partner, they have
less partner per investment.  They can't pay as much attention to
you as a VC on your board could.  How much is that extra attention
worth?  It will vary enormously from one partner to another.  There's
no consensus yet in the general case.  So for now this is something
startups are deciding individually.Till now, VCs' claims about how much value they added were sort of
like the government's. Hidden on Mysterious Island is the legendary Counterclockwise Crystal.  Maybe they made you feel better, but you
had no choice in the matter, if you needed money on the scale only
VCs could supply.  Now that VCs have competitors, that's going to
put a market price on the help they offer.  The interesting thing
is, no one knows yet what it will be.Do startups that want to get really big need the sort of advice and
connections only the top VCs can supply?  Or would super-angel money
do just as well?  The VCs will say you need them, and the super-angels
will say you don't.  But the truth is, no one knows yet, not even
the VCs and super-angels themselves.   All the super-angels know
is that their new model seems promising enough to be worth trying,
and all the VCs know is that it seems promising enough to worry
about.RoundsWhatever the outcome, the conflict between VCs and super-angels is
good news for founders.  And not just for the obvious reason that
more competition for deals means better terms.  The whole shape of
deals is changing.One of the biggest differences between angels and VCs is the amount
of your company they want.  VCs want a lot.  In a series A round
they want a third of your company, if they can get it.  They don't
care much how much they pay for it, but they want a lot because the
number of series A investments they can do is so small.  In a
traditional series A investment, at least one partner from the VC
fund takes a seat on your board.  
[4]
 Since board seats last about
5 years and each partner can't handle more than about 10 at once,
that means a VC fund can only do about 2 series A deals per partner
per year. And that means they need to get as much of the company
as they can in each one.  You'd have to be a very promising startup
indeed to get a VC to use up one of his 10 board seats for only a
few percent of you.Since angels generally don't take board seats, they don't have this
constraint.  They're happy to buy only a few percent of you.  And
although the super-angels are in most respects mini VC funds, they've
retained this critical property of angels.  They don't take board
seats, so they don't need a big percentage of your company.Though that means you'll get correspondingly less attention from
them, it's good news in other respects.  Founders never really liked
giving up as much equity as VCs wanted.  It was a lot of the company
to give up in one shot.  Most founders doing series A deals would
prefer to take half as much money for half as much stock, and then
see what valuation they could get for the second half of the stock
after using the first half of the money to increase its value.  But
VCs never offered that option.Now startups have another alternative.  Now it's easy to raise angel
rounds about half the size of series A rounds.  Many of the startups
we fund are taking this route, and I predict that will be true of
startups in general.A typical big angel round might be $600k on a convertible note with
a valuation cap of $4 million premoney.  Meaning that when the note
converts into stock (in a later round, or upon acquisition), the
investors in that round will get .6 / 4.6, or 13% of the company.
That's a lot less than the 30 to 40% of the company you usually
give up in a series A round if you do it so early.  
[5]But the advantage of these medium-sized rounds is not just that
they cause less dilution.  You also lose less control.  After an
angel round, the founders almost always still have control of the
company, whereas after a series A round they often don't.  The
traditional board structure after a series A round is two founders,
two VCs, and a (supposedly) neutral fifth person.  Plus series A
terms usually give the investors a veto over various kinds of
important decisions, including selling the company.  Founders usually
have a lot of de facto control after a series A, as long as things
are going well.  But that's not the same as just being able to do
what you want, like you could before.A third and quite significant advantage of angel rounds is that
they're less stressful to raise.  Raising a traditional series A
round has in the past taken weeks, if not months.  When a VC firm
can only do 2 deals per partner per year, they're careful about
which they do.  To get a traditional series A round you have to go
through a series of meetings, culminating in a full partner meeting
where the firm as a whole says yes or no.  That's the really scary
part for founders: not just that series A rounds take so long, but
at the end of this long process the VCs might still say no.  The
chance of getting rejected after the full partner meeting averages
about 25%.  At some firms it's over 50%.Fortunately for founders, VCs have been getting a lot faster.
Nowadays Valley VCs are more likely to take 2 weeks than 2 months.
But they're still not as fast as angels and super-angels, the most
decisive of whom sometimes decide in hours.Raising an angel round is not only quicker, but you get feedback
as it progresses.  An angel round is not an all or nothing thing
like a series A.  It's composed of multiple investors with varying
degrees of seriousness, ranging from the upstanding ones who commit
unequivocally to the jerks who give you lines like "come back to
me to fill out the round." You usually start collecting money from
the most committed investors and work your way out toward the
ambivalent ones, whose interest increases as the round fills up.But at each point you know how you're doing.  If investors turn
cold you may have to raise less, but when investors in an angel
round turn cold the process at least degrades gracefully, instead
of blowing up in your face and leaving you with nothing, as happens
if you get rejected by a VC fund after a full partner meeting.
Whereas if investors seem hot, you can not only close the round
faster, but now that convertible notes are becoming the norm,
actually raise the price to reflect demand.ValuationHowever, the VCs have a weapon they can use against the super-angels,
and they have started to use it.   VCs have started making angel-sized
investments too.  The term "angel round" doesn't mean that all the
investors in it are angels; it just describes the structure of the
round.  Increasingly the participants include VCs making investments
of a hundred thousand or two.  And when VCs invest in angel rounds
they can do things that super-angels don't like.  VCs are quite
valuation-insensitive in angel rounds—partly because they are
in general, and partly because they don't care that much about the
returns on angel rounds, which they still view mostly as a way to
recruit startups for series A rounds later.  So VCs who invest in
angel rounds can blow up the valuations for angels and super-angels
who invest in them. 
[6]Some super-angels seem to care about valuations.  Several turned
down YC-funded startups after Demo Day because their valuations
were too high.  This was not a problem for the startups; by definition
a high valuation means enough investors were willing to accept it.
But it was mysterious to me that the super-angels would quibble
about valuations.  Did they not understand that the big returns
come from a few big successes, and that it therefore mattered far
more which startups you picked than how much you paid for them?After thinking about it for a while and observing certain other
signs, I have a theory that explains why the super-angels may be
smarter than they seem.  It would make sense for super-angels to
want low valuations if they're hoping to invest in startups that
get bought early.  If you're hoping to hit the next Google, you
shouldn't care if the valuation is 20 million.  But if you're looking
for companies that are going to get bought for 30 million, you care.
If you invest at 20 and the company gets bought for 30, you only
get 1.5x.  You might as well buy Apple.So if some of the super-angels were looking for companies that could
get acquired quickly, that would explain why they'd care about
valuations.  But why would they be looking for those?   Because
depending on the meaning of "quickly," it could actually be very
profitable.  A company that gets acquired for 30 million is a failure
to a VC, but it could be a 10x return for an angel, and moreover,
a quick 10x return.  Rate of return is what matters in
investing—not the multiple you get, but the multiple per year.
If a super-angel gets 10x in one year, that's a higher rate of
return than a VC could ever hope to get from a company that took 6
years to go public.  To get the same rate of return, the VC would
have to get a multiple of 10^6—one million x.  Even Google
didn't come close to that.So I think at least some super-angels are looking for companies
that will get bought.  That's the only rational explanation for
focusing on getting the right valuations, instead of the right
companies.  And if so they'll be different to deal with than VCs.
They'll be tougher on valuations, but more accommodating if you want
to sell early.PrognosisWho will win, the super-angels or the VCs?  I think the answer to
that is, some of each.  They'll each become more like one another.
The super-angels will start to invest larger amounts, and the VCs
will gradually figure out ways to make more, smaller investments
faster.  A decade from now the players will be hard to tell apart,
and there will probably be survivors from each group.What does that mean for founders?  One thing it means is that the
high valuations startups are presently getting may not last forever.
To the extent that valuations are being driven up by price-insensitive
VCs, they'll fall again if VCs become more like super-angels and
start to become more miserly about valuations.  Fortunately if this
does happen it will take years.The short term forecast is more competition between investors, which
is good news for you.  The super-angels will try to undermine the
VCs by acting faster, and the VCs will try to undermine the
super-angels by driving up valuations.  Which for founders will
result in the perfect combination: funding rounds that close fast,
with high valuations.But remember that to get that combination, your startup will have
to appeal to both super-angels and VCs.  If you don't seem like you
have the potential to go public, you won't be able to use VCs to
drive up the valuation of an angel round.There is a danger of having VCs in an angel round: the so-called
signalling risk.  If VCs are only doing it in the hope of investing
more later, what happens if they don't?  That's a signal to everyone
else that they think you're lame.How much should you worry about that?  The seriousness of signalling
risk depends on how far along you are.  If by the next time you
need to raise money, you have graphs showing rising revenue or
traffic month after month, you don't have to worry about any signals
your existing investors are sending.  Your results will speak for
themselves.  
[7]Whereas if the next time you need to raise money you won't yet have
concrete results, you may need to think more about the message your
investors might send if they don't invest more.  I'm not sure yet
how much you have to worry, because this whole phenomenon of VCs
doing angel investments is so new. But my instincts tell me you
don't have to worry much.  Signalling risk smells like one of those
things founders worry about that's not a real problem.  As a rule,
the only thing that can kill a good startup is the startup itself.
Startups hurt themselves way more often than competitors hurt them,
for example.  I suspect signalling risk is in this category too.One thing YC-funded startups have been doing to mitigate the risk
of taking money from VCs in angel rounds is not to take too much
from any one VC.  Maybe that will help, if you have the luxury of
turning down money.Fortunately, more and more startups will.  After decades of competition
that could best be described as intramural, the startup funding
business is finally getting some real competition.  That should
last several years at least, and maybe a lot longer. Unless there's
some huge market crash, the next couple years are going to be a
good time for startups to raise money.  And that's exciting because
it means